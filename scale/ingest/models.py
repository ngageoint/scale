"""Defines the database models related to ingesting files"""
from __future__ import unicode_literals

import datetime
import logging
import operator
import os
from functools import reduce

from collections import namedtuple

import django.utils.timezone as timezone
import django.contrib.postgres.fields
from django.contrib.postgres.indexes import GinIndex
from django.db import models, transaction
from django.db.models import Q
from django.utils.timezone import now

from data.data.data import Data
from data.data.value import JsonValue
from ingest.messages.create_ingest_jobs import create_scan_ingest_job_message, create_strike_ingest_job_message
from ingest.scan.configuration.scan_configuration import ScanConfiguration
from ingest.scan.configuration.json.configuration_v6 import ScanConfigurationV6
from ingest.scan.configuration.exceptions import InvalidScanConfiguration
from ingest.scan.scanners.exceptions import ScanIngestJobAlreadyLaunched
from ingest.strike.configuration.strike_configuration import StrikeConfiguration
from ingest.strike.configuration.json.configuration_v6 import StrikeConfigurationV6, convert_strike_config_to_v6_json
from ingest.strike.configuration.exceptions import InvalidStrikeConfiguration
from job.models import JobType
from job.messages.process_job_input import create_process_job_input_messages
from job.messages.cancel_jobs import create_cancel_jobs_messages
from messaging.manager import CommandMessageManager
from queue.models import Queue
from storage.exceptions import InvalidDataTypeTag
from storage.media_type import get_media_type
from trigger.models import TriggerEvent
from util.file_size import file_size_to_string
from util import rest as rest_utils

logger = logging.getLogger(__name__)


class IngestCounts(object):
    """Represents ingest status values for a specific time slot.

    :keyword time: The time slot being counted.
    :type time: datetime.datetime
    :keyword files: The number of files ingested for the time slot.
    :type files: int
    :keyword size: The total size of all files ingested for the time slot in bytes.
    :type size: int
    """

    def __init__(self, time, files=0, size=0):
        self.time = time
        self.files = files
        self.size = size


class IngestStatus(object):
    """Represents ingest status values for a strike process.

    :keyword strike: The strike process that generated the ingests being counted.
    :type strike: :class:`strike.models.Strike`
    :keyword most_recent: The date/time of the last ingest generated by the strike process.
    :type most_recent: datetime.datetime
    :keyword files: The total number of files ingested by the strike process.
    :type files: int
    :keyword size: The total size of all files ingested by the strike process in bytes.
    :type size: int
    :keyword values: A list of values that summarize work done by the strike process.
    :type values: list[:class:`ingest.models.IngestCounts`]
    """

    def __init__(self, strike=None, most_recent=None, files=0, size=0, values=None):
        self.strike = strike
        self.most_recent = most_recent
        self.files = files
        self.size = size
        self.values = values or []


class IngestManager(models.Manager):
    """Provides additional methods for handling ingests."""

    def create_ingest(self, file_name, workspace, scan_id=None, strike_id=None):
        """Creates a new ingest for the given file name. The database save is the caller's responsibility.

        :param file_name: The name of the file being ingested
        :type file_name: string
        :param workspace:
        :type workspace: string
        :param recipe: The name of the recipe to kick off after ingest
        :type recipe: string
        :param scan_id:
        :type scan_id: int
        :param strike_id:
        :type strike_id: int
        :returns: The new ingest model
        :rtype: :class:`ingest.models.Ingest`
        """

        ingest = Ingest()

        if scan_id:
            ingest.scan_id = scan_id
        if strike_id:
            ingest.strike_id = strike_id

        ingest.file_name = file_name
        ingest.media_type = get_media_type(ingest.file_name)
        ingest.workspace = workspace

        return ingest

    def filter_ingests(self, source_file_id=None, started=None, ended=None, statuses=None, scan_ids=None,
                       strike_ids=None, file_name=None, order=None):
        """Returns a query for ingest models that filters on the given fields. The returned query includes the related
        strike, scan, source_file, and source_file.workspace fields, except for the strike.configuration,
        scan.configuration, and source_file.workspace.json_config fields.

        :param source_file_id: Query ingests for this source file ID.
        :type source_file_id: int
        :param started: Query ingests updated after this amount of time.
        :type started: :class:`datetime.datetime`
        :param ended: Query ingests updated before this amount of time.
        :type ended: :class:`datetime.datetime`
        :param statuses: Query ingests with the a specific process status.
        :type statuses: [string]
        :param scan_ids: Query ingests created by a specific scan processor.
        :type scan_ids: [string]
        :param strike_ids: Query ingests created by a specific strike processor.
        :type strike_ids: [string]
        :param file_name: Query ingests with a specific file name.
        :type file_name: string
        :param order: A list of fields to control the sort order.
        :type order: [string]
        :returns: The ingest query
        :rtype: :class:`django.db.models.QuerySet`
        """

        # Fetch a list of ingests
        ingests = self.select_related('strike', 'scan', 'workspace', 'new_workspace', 'job')
        ingests = ingests.select_related('source_file', 'source_file__workspace')
        ingests = ingests.defer('strike__configuration', 'scan__configuration', 'workspace__json_config')
        ingests = ingests.defer('new_workspace__json_config', 'job__input', 'job__output')
        ingests = ingests.defer('source_file__workspace__json_config')

        # Apply time range filtering
        if started:
            ingests = ingests.filter(last_modified__gte=started)
        if ended:
            ingests = ingests.filter(last_modified__lte=ended)

        if source_file_id:
            ingests = ingests.filter(source_file_id=source_file_id)
        if statuses:
            ingests = ingests.filter(status__in=statuses)
        if scan_ids:
            ingests = ingests.filter(scan_id__in=scan_ids)
        if strike_ids:
            ingests = ingests.filter(strike_id__in=strike_ids)
        if file_name:
            ingests = ingests.filter(file_name__contains=file_name)

        # Apply sorting
        if order:
            ingests = ingests.order_by(*order)
        else:
            ingests = ingests.order_by('last_modified')
        return ingests

    def get_ingest_job_type(self):
        """Returns the Scale Ingest job type

        :returns: The ingest job type
        :rtype: :class:`job.models.JobType`
        """

        return JobType.objects.get(name='scale-ingest', version='1.0.0')

    def get_ingests(self, started=None, ended=None, statuses=None, scan_ids=None, strike_ids=None, file_name=None,
                    order=None):
        """Returns a list of ingests within the given time range.

        :param started: Query ingests updated after this amount of time.
        :type started: :class:`datetime.datetime`
        :param ended: Query ingests updated before this amount of time.
        :type ended: :class:`datetime.datetime`
        :param statuses: Query ingests with the a specific process status.
        :type statuses: [string]
        :param scan_ids: Query ingests created by a specific scan processor.
        :type scan_ids: list[string]
        :param strike_ids: Query ingests created by a specific strike processor.
        :type strike_ids: list[string]
        :param file_name: Query ingests with the a specific file name.
        :type file_name: string
        :param order: A list of fields to control the sort order.
        :type order: list[string]
        :returns: The list of ingests that match the time range.
        :rtype: list[:class:`ingest.models.Ingest`]
        """

        return self.filter_ingests(started=started, ended=ended, statuses=statuses, scan_ids=scan_ids,
                                   strike_ids=strike_ids, file_name=file_name, order=order)

    def get_ingests_by_scan(self, scan_id, file_names=None):
        """Returns a list of ingests associated with a scan and optionally files

        :param scan_id: Query ingests created by a specific scan processor.
        :type scan_id: list[string]
        :param file_names: Query ingests with the specific file names.
        :type file_names: list[string]
        :returns: The list of ingests that match the scan and file_names.
        :rtype: list[:class:`ingest.models.Ingest`]
        """

        # Fetch a list of ingests
        ingests = Ingest.objects.all()

        if scan_id:
            ingests = ingests.filter(scan_id=scan_id)
        if file_names:
            ingests = ingests.filter(file_name__in=file_names)

        return ingests

    def get_details(self, ingest_id, is_staff=False):
        """Gets additional details for the given ingest model based on related model attributes.

        :param ingest_id: The unique identifier of the ingest.
        :type ingest_id: int
        :param is_staff: Whether the requesting user is a staff member
        :type is_staff: bool
        :returns: The ingest with extra related attributes.
        :rtype: :class:`ingest.models.Ingest`
        """

        # Attempt to fetch the requested ingest
        ingest = Ingest.objects.select_related('scan', 'scan__job', 'scan__dry_run_job', 'strike', 'strike__job',
                                               'strike__job__job_type', 'workspace', 'new_workspace', 'job',
                                               'source_file', 'source_file__workspace')
        ingest = ingest.defer('source_file__workspace__json_config')
        ingest = ingest.get(pk=ingest_id)
        ingest.admin_view = is_staff
        if ingest.strike:
            ingest.strike.admin_view = is_staff

        return ingest

    def get_recipe_source_config(self, ingest_id):
        """Returns the strike/scan recipe configuration for the given ingest id"""

        ingest = Ingest.objects.get(pk=ingest_id)
        if ingest.strike:
            return Strike.objects.get(pk=ingest.strike.id).get_configuration()['recipe']
        else:
            return Scan.objects.get(pk=ingest.scan.id).get_configuration()['recipe']

    def get_status(self, started=None, ended=None, use_ingest_time=False):
        """Returns ingest status information within the given time range grouped by strike process.

        :param started: Query ingests updated after this amount of time.
        :type started: :class:`datetime.datetime`
        :param ended: Query ingests updated before this amount of time.
        :type ended: :class:`datetime.datetime`
        :param use_ingest_time: Whether or not to group the status values by ingest time (False) or data time (True).
        :type use_ingest_time: bool
        :returns: The list of ingest status models that match the time range.
        :rtype: list[:class:`ingest.models.IngestStatus`]
        """

        # Fetch a list of ingests
        ingests = Ingest.objects.filter(status='INGESTED')
        ingests = ingests.select_related('strike')
        ingests = ingests.defer('strike__configuration')

        # Apply time range filtering
        if started:
            if use_ingest_time:
                ingests = ingests.filter(ingest_ended__gte=started)
            else:
                ingests = ingests.filter(data_ended__gte=started)
        if ended:
            if use_ingest_time:
                ingests = ingests.filter(ingest_ended__lte=ended)
            else:
                ingests = ingests.filter(data_started__lte=ended)

        # Apply sorting
        if use_ingest_time:
            ingests = ingests.order_by('ingest_ended')
        else:
            ingests = ingests.order_by('data_started')

        groups = self._group_by_time(ingests, use_ingest_time)
        return [self._fill_status(status, time_slots, started, ended) for status, time_slots in groups.iteritems()]

    def start_ingest_tasks(self, ingests, scan_id=None, strike_id=None):
        """Starts a batch of tasks for the given scan in an atomic transaction.

        One of scan_id or strike_id must be set.

        :param ingests: The ingest models
        :type ingests: list[:class:`ingest.models.Ingest`]
        :param scan_id: ID of Scan that generated ingest
        :type scan_id: int
        :param strike_id: ID of Strike that generated ingest
        :type strike_id: int
        """
        
        messages = []
        for ingest in ingests:
            logger.debug('Creating ingest task for %s', ingest.file_name)
            
            if scan_id:
                # TODO: Need to make sure scans work
                messages.append(create_scan_ingest_job_message(ingest.id, scan_id))
            elif strike_id:
                messages.append(create_strike_ingest_job_message(ingest.id, strike_id))
            else:
                raise Exception('One of scan_id or strike_id must be set')

        CommandMessageManager().send_messages(messages)
            
        logger.debug('Successfully created ingest task for %s', ingest.file_name)

    def _group_by_time(self, ingests, use_ingest_time):
        """Groups the given ingests by hourly time slots.

        :param ingests: Query ingests updated after this amount of time.
        :type ingests: list[:class:`ingest.models.Ingest`]
        :param use_ingest_time: Whether or not to group the status values by ingest time (False) or data time (True).
        :type use_ingest_time: bool
        :returns: A mapping of ingest status models to hourly groups of counts.
        :rtype: dict[:class:`ingest.models.IngestStatus`, dict[datetime.datetime, :class:`ingest.models.IngestCounts`]]
        """

        # Build a mapping of all possible strike processes
        strike_map = {}
        slot_map = {}
        for strike in Strike.objects.all():
            strike_map[strike] = IngestStatus(strike)
            slot_map[strike] = {}

        # Build a mapping of ingest status to time slots
        for ingest in ingests:

            # Initialize the mappings for the first strike
            if ingest.strike not in strike_map:
                logger.error('Missing strike process mapping: %s', ingest.strike_id)
                continue

            # Check whether there is a valid date for the requested query
            dated = ingest.ingest_ended if use_ingest_time else ingest.data_started
            if dated:
                ingest_status = strike_map[ingest.strike]
                time_slots = slot_map[ingest.strike]
                self._update_status(ingest_status, time_slots, ingest, dated)

        return {strike_map[strike]: slot_map[strike] for strike in strike_map}

    def _update_status(self, ingest_status, time_slots, ingest, dated):
        """Updates the given ingest status model based on attributes of an ingest model.

        :param ingest_status: The ingest status to update.
        :type ingest_status: :class:`ingest.models.IngestStatus`
        :param time_slots: A mapping of hourly time slots to ingest status counts.
        :type time_slots: dict[datetime.datetime, :class:`ingest.models.IngestCounts`]
        :param ingest: The ingest model that should be counted.
        :type ingest: :class:`ingest.models.Ingest`
        :returns: The ingest status model after the counts are updated.
        :rtype: :class:`ingest.models.IngestStatus`
        """

        # Calculate the hourly time slot the record falls within
        time_slot = datetime.datetime(dated.year, dated.month, dated.day, dated.hour, tzinfo=timezone.utc)

        # Update the values for the current time slot
        if time_slot not in time_slots:
            time_slots[time_slot] = IngestCounts(time_slot)
        values = time_slots[time_slot]
        values.files += 1
        values.size += ingest.file_size

        # Update the summary values for the ingest status
        ingest_status.files += 1
        ingest_status.size += ingest.file_size
        if not ingest_status.most_recent or dated > ingest_status.most_recent:
            ingest_status.most_recent = dated

        return ingest_status

    def _fill_status(self, ingest_status, time_slots, started=None, ended=None):
        """Fills all the values for the given ingest status using a specified time range and grouped values.

        This method ensures that each hourly bin has a value, even when no data actually exists.

        :param ingest_status: The ingest status to fill with values.
        :type ingest_status: :class:`ingest.models.IngestStatus`
        :param time_slots: A mapping of hourly time slots to ingest status counts.
        :type time_slots: dict[datetime.datetime, :class:`ingest.models.IngestCounts`]
        :param started: The start of the time range that needs to be filled.
        :type started: datetime.datetime
        :param ended: The end of the time range that needs to be filled.
        :type ended: datetime.datetime
        :returns: The ingest status model after the values array is filled.
        :rtype: :class:`ingest.models.IngestStatus`
        """

        # Make sure we have a valid time range
        started = started if started else datetime.datetime.combine(timezone.now().date(), datetime.time.min)
        ended = ended if ended else datetime.datetime.combine(timezone.now().date(), datetime.time.max)

        # Build a list of values for each hourly time slot including zero value place holders where needed
        duration = ended.date() - started.date()
        for day in range(duration.days + 1):
            for hour in range(24):
                dated = started + datetime.timedelta(days=day)
                time_slot = datetime.datetime(dated.year, dated.month, dated.day, hour, tzinfo=timezone.utc)
                status_vals = time_slots[time_slot] if time_slot in time_slots else IngestCounts(time_slot)
                ingest_status.values.append(status_vals)

        return ingest_status


class Ingest(models.Model):
    """Represents an instance of a file being ingested into a workspace

    :keyword file_name: The name of the file
    :type file_name: :class:`django.db.models.CharField`
    :keyword strike: The Strike process that created this ingest
    :type strike: :class:`django.db.models.ForeignKey`
    :keyword scan: The Scan process that created this ingest
    :type scan: :class:`django.db.models.ForeignKey`
    :keyword status: The status of the file ingest process
    :type status: :class:`django.db.models.CharField`

    :keyword transfer_started: When the transfer to the workspace started
    :type transfer_started: :class:`django.db.models.DateTimeField`
    :keyword transfer_ended: When the transfer to the workspace ended
    :type transfer_ended: :class:`django.db.models.DateTimeField`
    :keyword bytes_transferred: The total number of bytes transferred so far
    :type bytes_transferred: :class:`django.db.models.BigIntegerField`

    :keyword media_type: The IANA media type of the file
    :type media_type: :class:`django.db.models.CharField`
    :keyword file_size: The size of the file in bytes
    :type file_size: :class:`django.db.models.BigIntegerField`
    :keyword data_type_tags: An array of data type "tags" for the file
    :type data_type_tags: :class:`django.db.models.ArrayField`

    :keyword file_path: The relative path for where the file is stored in the workspace
    :type file_path: :class:`django.db.models.CharField`
    :keyword workspace: The workspace where the file was transferred
    :type workspace: :class:`django.db.models.ForeignKey`
    :keyword new_file_path: The relative path for where the file should be moved as part of ingesting
    :type new_file_path: :class:`django.db.models.CharField`
    :keyword new_workspace: The new workspace to move the file into as part of ingesting
    :type new_workspace: :class:`django.db.models.ForeignKey`

    :keyword job: The ingest job that is processing this ingest
    :type job: :class:`django.db.models.ForeignKey`
    :keyword ingest_started: When the ingest was started
    :type ingest_started: :class:`django.db.models.DateTimeField`
    :keyword ingest_ended: When the ingest ended
    :type ingest_ended: :class:`django.db.models.DateTimeField`
    :keyword source_file: A reference to the source file that was stored by this ingest
    :type source_file: :class:`django.db.models.ForeignKey`
    :keyword data_started: The start time of the data in this source file
    :type data_started: :class:`django.db.models.DateTimeField`
    :keyword data_ended: The end time of the data in this source file
    :type data_ended: :class:`django.db.models.DateTimeField`

    :keyword created: When the ingest model was created
    :type created: :class:`django.db.models.DateTimeField`
    :keyword last_modified: When the ingest model was last modified
    :type last_modified: :class:`django.db.models.DateTimeField`
    """
    INGEST_STATUSES = (
        ('TRANSFERRING', 'TRANSFERRING'),
        ('TRANSFERRED', 'TRANSFERRED'),
        ('DEFERRED', 'DEFERRED'),
        ('QUEUED', 'QUEUED'),
        ('INGESTING', 'INGESTING'),
        ('INGESTED', 'INGESTED'),
        ('ERRORED', 'ERRORED'),
        ('DUPLICATE', 'DUPLICATE'),
    )

    file_name = models.CharField(max_length=250, db_index=True)
    scan = models.ForeignKey('ingest.Scan', on_delete=models.PROTECT, null=True)
    strike = models.ForeignKey('ingest.Strike', on_delete=models.PROTECT, null=True)
    status = models.CharField(choices=INGEST_STATUSES, default='TRANSFERRING', max_length=50, db_index=True)

    bytes_transferred = models.BigIntegerField(blank=True, null=True)
    transfer_started = models.DateTimeField(blank=True, null=True)
    transfer_ended = models.DateTimeField(blank=True, null=True)

    media_type = models.CharField(max_length=250, blank=True)
    file_size = models.BigIntegerField(blank=True, null=True)
    data_type_tags = django.contrib.postgres.fields.ArrayField(models.CharField(max_length=250, blank=True), default=list)

    file_path = models.CharField(max_length=1000, blank=True)
    workspace = models.ForeignKey('storage.Workspace', blank=True, null=True, related_name='+')
    new_file_path = models.CharField(max_length=1000, blank=True)
    new_workspace = models.ForeignKey('storage.Workspace', blank=True, null=True, related_name='+')

    job = models.ForeignKey('job.Job', blank=True, null=True)
    ingest_started = models.DateTimeField(blank=True, null=True)
    ingest_ended = models.DateTimeField(blank=True, null=True, db_index=True)

    source_file = models.ForeignKey('storage.ScaleFile', blank=True, null=True)
    data_started = models.DateTimeField(blank=True, null=True, db_index=True)
    data_ended = models.DateTimeField(blank=True, null=True, db_index=True)

    created = models.DateTimeField(auto_now_add=True)
    last_modified = models.DateTimeField(auto_now=True)

    objects = IngestManager()

    def add_data_type_tag(self, tag):
        """Adds a new data type tag to the file.

        :param tag: The data type tag to add
        :type tag: string
        """


        tags = self.get_data_type_tags()
        tags.add(tag)
        self._set_data_type_tags(tags)

    def get_data_type_tags(self):
        """Returns the set of data type tags associated with this file

        :returns: The set of data type tags
        :rtype: set of string
        """

        return set(self.data_type_tags)

    def add_file(self, file_name, workspace, scan_id=None, strike_id=None):
        """Add file source metadata to ingest record

        :param file_name: File name excluding full path
        :type file_name: string
        :param workspace:
        :type workspace: string
        :param scan_id:
        :type scan_id: int
        :param strike_id:
        :type strike_id: int
        """

        if scan_id:
            self.scan_id = scan_id
        if strike_id:
            self.strike_id = strike_id

        self.file_name = file_name
        self.media_type = get_media_type(self.file_name)
        self.workspace = workspace

        logger.info('New file on %s: %s', self.workspace.name, self.file_name)

    def is_there_rule_match(self, file_handler, workspaces, no_match_status=None):
        """Applies rules to an ingest record, determining if there is a match and updating as indicated in rule match

        :param file_handler: Rules to be matched against the ingest record
        :type: :class: `ingest.handlers.file_handler.FileHandler`
        :param workspaces: mimetype to workspace mapping
        :type: dict
        :param no_match_status: Optional status to apply when rules aren't matched
        :type: string
        :return: The ingest record if matched otherwise None
        :rtype: :class:`ingest.models.Ingest`
        """

        matched = True
        logger.info('Applying rules to %s (%s, %s)',
                    self.file_name, self.media_type, file_size_to_string(self.file_size))
        matched_rule = file_handler.match_file_name(self.file_name)
        if matched_rule:
            for data_type_tag in matched_rule.data_types:
                self.add_data_type_tag(data_type_tag)
            file_path = self.file_path
            if matched_rule.new_file_path:
                today = now()
                year_dir = str(today.year)
                month_dir = '%02d' % today.month
                day_dir = '%02d' % today.day
                self.new_file_path = os.path.join(matched_rule.new_file_path, year_dir, month_dir, day_dir,
                                                  self.file_name)
                file_path = self.new_file_path
            workspace_name = self.workspace.name
            if matched_rule.new_workspace:
                self.new_workspace = workspaces[matched_rule.new_workspace]
                workspace_name = self.new_workspace.name
            if self.new_file_path or self.new_workspace:
                logger.info('Rule match, %s will be moved to %s on workspace %s',
                            self.file_name, file_path, workspace_name)
            else:
                logger.info('Rule match, %s will be registered as %s on workspace %s',
                            self.file_name, file_path, workspace_name)
        else:
            matched = False
            if no_match_status:
                logger.info('No rule match for %s, file is being set to %s', self.file_name, no_match_status)
                self.status = no_match_status
            else:
                logger.info('No rule match for %s, file is being skipped', self.file_name)

        return matched

    def _set_data_type_tags(self, tags):
        """Sets the data type tags on the model

        :param tags: The data type tags
        :type tags: set of string
        """

        self.data_type_tags = list(tags)

    def get_ingest_source_event(self):
        """Returns the event that triggered the ingest
        strike or scan
        """

        if self.strike:
            return self.strike
        elif self.scan:
            return self.scan
        else:
            logger.info('No source strike or scan for ingest %s' % self.id)

    def get_recipe_name(self):
        """Returns the """

        configuration = None
        if self.strike:
            configuration = self.strike.get_v6_configuration_json()
        elif self.scan:
            configuration = self.scan.get_v6_configuration_json()

        if 'recipe' in configuration:
            return configuration['recipe']['name']
        else:
            return None

    class Meta(object):
        """meta information for database"""
        db_table = 'ingest'
        indexes = [GinIndex(fields=['file_name'])]


class IngestEventManager(models.Manager):
    """Manages the IngestEvent model"""

    STRIKE_TYPE = 'STRIKE'
    SCAN_TYPE = 'SCAN'
    MANUAL_TYPE = 'MANUAL'

    def create_manual_ingest_event(self, ingest_id, description, occurred):
        """Creates a new ingest event and returns the event model.

        :param ingest_id: The ingest that triggered the strike
        :type ingest_id:
        :param description: The JSON description of the event as a dict
        :type description: dict
        :param occurred: When the event occurred
        :type occurred: :class:`datetime.datetime`
        :returns: The new trigger event
        :rtype: :class:`ingest.models.IngestEvent`
        """

        if ingest_id is None:
             raise Exception('Ingest event must have a valid ingest')

        event = IngestEvent()
        event.type = IngestEventManager.MANUAL_TYPE
        event.ingest_id = ingest_id
        event.description = description
        event.occurred = occurred
        event.save()

        return event

    def create_strike_ingest_event(self, ingest_id, strike, description, occurred):
        """Creates a new ingest event and returns the event model. The given strike model must have already
        been saved in the database (it must have an ID). The returned ingest event model will be saved in the database.

        :param ingest_id: The ingest that triggered the strike
        :type ingest_id:
        :param strike: The scan that triggered the event
        :type strike: :class:`ingest.models.Strike`
        :param description: The JSON description of the event as a dict
        :type description: dict
        :param occurred: When the event occurred
        :type occurred: :class:`datetime.datetime`
        :returns: The new trigger event
        :rtype: :class:`ingest.models.IngestEvent`
        """

        if strike is None:
            raise Exception('Ingest event must have a valid Strike')
        if description is None:
            raise Exception('Ingest event must have a JSON description')
        if occurred is None:
            raise Exception('Trigger event must have a timestamp')
        if ingest_id is None:
             raise Exception('Ingest event must have a valid ingest')

        event = IngestEvent()
        event.type = IngestEventManager.STRIKE_TYPE
        event.ingest_id = ingest_id
        event.strike = strike
        event.description = description
        event.occurred = occurred
        event.save()

        return event

    def create_scan_ingest_event(self, ingest_id, scan, description, occurred):
        """Creates a new ingest event and returns the event model. The given scan model must have already
        been saved in the database (it must have an ID). The returned ingest event model will be saved in the database.

        :param ingest_id: The ingest that triggered the scan
        :type ingest_id:
        :param scan: The scan that triggered the event
        :type scan: :class:`ingest.models.Scan`
        :param description: The JSON description of the event as a dict
        :type description: dict
        :param occurred: When the event occurred
        :type occurred: :class:`datetime.datetime`
        :returns: The new trigger event
        :rtype: :class:`ingest.models.IngestEvent`
        """

        if scan is None:
            raise Exception('Ingest event must have a valid Scan')
        if description is None:
            raise Exception('Ingest event must have a JSON description')
        if occurred is None:
            raise Exception('Trigger event must have a timestamp')
        if ingest_id is None:
             raise Exception('Ingest event must have a valid ingest')

        event = IngestEvent()
        event.type = IngestEventManager.SCAN_TYPE
        event.ingest_id = ingest_id
        event.scan = scan
        event.description = description
        event.occurred = occurred
        event.save()

        return event

class IngestEvent(models.Model):
    """Represents an ingest event that triggered a recipe

    :keyword type: The type of ingest that occurred (strike/scan)
    :type type: :class:`django.db.models.CharField`
    :keyword ingest: The ingest that occurred
    :type ingest: :class:`django.db.models.ForeignKey`
    :keyword strike: The strike that triggered this event, possibly None (some events are not triggered by rules)
    :type strike: :class:`django.db.models.ForeignKey`
    :keyword scan: The scan that triggered this event, possibly None (some events are not triggered by rules)
    :type scan: :class:`django.db.models.ForeignKey`
    :keyword description: JSON description of the event. This will contain fields specific to the type of the trigger
        that occurred.
    :type description: :class:`django.contrib.postgres.fields.JSONField`
    :keyword occurred: When the event occurred
    :type occurred: :class:`django.db.models.DateTimeField`
    """
    type = models.CharField(db_index=True, max_length=50)
    ingest = models.ForeignKey('ingest.Ingest', blank=True, null=True, on_delete=models.PROTECT)
    strike = models.ForeignKey('ingest.Strike', blank=True, null=True, on_delete=models.PROTECT)
    scan = models.ForeignKey('ingest.Scan', blank=True, null=True, on_delete=models.PROTECT)
    description = django.contrib.postgres.fields.JSONField(default=dict)
    occurred = models.DateTimeField(db_index=True)

    objects = IngestEventManager()

    class Meta(object):
        """meta information for the db"""
        db_table = 'ingest_event'

ScanValidation = namedtuple('ScanValidation', ['is_valid', 'errors', 'warnings'])

class ScanManager(models.Manager):
    """Provides additional methods for handling Scan processes
    """

    @transaction.atomic
    def create_scan(self, name, title, description, configuration):
        """Creates a new Scan process with the given configuration and returns
        the new Scan model. All changes to the database will occur in an atomic transaction.

        :param name: The identifying name of this Scan process
        :type name: string
        :param title: The human-readable name of this Scan process
        :type title: string
        :param description: A description of this Scan process
        :type description: string
        :param configuration: The Scan configuration
        :type configuration: :class:`ingest.scan.configuration.scan_configuration.ScanConfiguration`
        :returns: The new Scan process
        :rtype: :class:`ingest.models.Scan`

        :raises :class:`ingest.scan.configuration.exceptions.InvalidScanConfiguration`: If the configuration is
            invalid.
        """

        # Validate the configuration, no exception is success
        configuration.validate()

        scan = Scan()
        scan.name = name
        scan.title = title
        scan.description = description
        scan.configuration = configuration.config_dict
        scan.save()

        return scan

    @transaction.atomic
    def edit_scan(self, scan_id, title=None, description=None, configuration=None):
        """Edits the given Scan process and saves the changes in the database. All database changes occur in an atomic
        transaction. An argument of None for a field indicates that the field should not change.

        :param scan_id: The unique identifier of the Scan process to edit
        :type scan_id: int
        :param title: The human-readable name of this Scan process
        :type title: string
        :param description: A description of this Scan process
        :type description: string
        :param configuration: The Scan process configuration
        :type configuration: :class:`ingest.scan.configuration.scan_configuration.ScanConfiguration`

        :raises :class:`ingest.scan.configuration.exceptions.InvalidScanConfiguration`: If the configuration is
            invalid.
        """

        scan = Scan.objects.select_for_update().get(pk=scan_id)

        if scan.job:
            raise ScanIngestJobAlreadyLaunched

        # Validate the configuration, no exception is success
        if configuration:
            configuration.validate()
            scan.configuration = configuration.config_dict

        # Update editable fields
        if title:
            scan.title = title
        if description:
            scan.description = description
        scan.save()

    def get_scan_job_type(self):
        """Returns the Scale Scan job type

        :returns: The Scan job type
        :rtype: :class:`job.models.JobType`
        """

        return JobType.objects.get(name='scale-scan', version='1.0.0')

    def get_scans(self, started=None, ended=None, names=None, order=None):
        """Returns a list of Scan processes within the given time range.

        :param started: Query Scan processes updated after this amount of time.
        :type started: :class:`datetime.datetime`
        :param ended: Query Scan processes updated before this amount of time.
        :type ended: :class:`datetime.datetime`
        :param names: Query Scan processes associated with the name.
        :type names: list[string]
        :param order: A list of fields to control the sort order.
        :type order: list[string]
        :returns: The list of Scan processes that match the time range.
        :rtype: list[:class:`ingest.models.Scan`]
        """

        # Fetch a list of scans
        scans = Scan.objects.select_related('job', 'job__job_type') \
                            .select_related('dry_run_job', 'dry_run_job__job_type') \
                            .defer('configuration')

        # Apply time range filtering
        if started:
            scans = scans.filter(last_modified__gte=started)
        if ended:
            scans = scans.filter(last_modified__lte=ended)

        # Apply additional filters
        if names:
            scans = scans.filter(reduce(operator.or_, (Q(name__contains=name) for name in names)))

        # Apply sorting
        if order:
            scans = scans.order_by(*order)
        else:
            scans = scans.order_by('last_modified')
        return scans

    def get_details(self, scan_id):
        """Returns the Scan process for the given ID with all detail fields included.

        :param scan_id: The unique identifier of the Scan process.
        :type scan_id: int
        :returns: The Scan process with all detail fields included.
        :rtype: :class:`ingest.models.Scan`
        """

        scan = Scan.objects.select_related('job', 'job__job_type')
        scan = scan.select_related('dry_run_job', 'dry_run_job__job_type')
        scan = scan.get(pk=scan_id)

        return scan

    @transaction.atomic
    def queue_scan(self, scan_id, dry_run=True):
        """Retrieves a Scan model and uses metadata to place a job to run the
        Scan process on the queue. All changes to the database will occur in an
        atomic transaction.

        :param scan_id: The unique identifier of the Scan process.
        :type scan_id: int
        :param dry_run: Whether the scan will execute as a dry run
        :type dry_run: bool
        :returns: The new Scan process
        :rtype: :class:`ingest.models.Scan`
        """

        scan = Scan.objects.select_for_update().get(pk=scan_id)
        scan_type = self.get_scan_job_type()

        event_description = {'scan_id': scan.id}

        job_data = Data()
        job_data.add_value(JsonValue('SCAN_ID', scan.id))
        job_data.add_value(JsonValue('DRY_RUN', dry_run))

        if scan.job:
            raise ScanIngestJobAlreadyLaunched

        job_id = None
        if dry_run:
            event = TriggerEvent.objects.create_trigger_event('DRY_RUN_SCAN_CREATED', None, event_description, now())
            scan.dry_run_job = Queue.objects.queue_new_job_v6(scan_type, job_data, event)
            job_id = scan.dry_run_job.id
        else:
            event = TriggerEvent.objects.create_trigger_event('SCAN_CREATED', None, event_description, now())
            scan.job = Queue.objects.queue_new_job_v6(scan_type, job_data, event)
            job_id = scan.job.id

        scan.save()
        CommandMessageManager().send_messages(create_process_job_input_messages([job_id]))

        return scan

    def validate_scan_v6(self, configuration):
        """Validates the given configuration for creating a new scan process

        :param configuration: The scan configuration
        :type configuration: dict
        :returns: The scan validation
        :rtype: :class:`strike.models.ScanValidation`
        """

        is_valid = True
        errors = []
        warnings = []

        try:
            config = ScanConfigurationV6(configuration, do_validate=True).get_configuration()
            warnings = config.validate()
        except InvalidScanConfiguration as ex:
            is_valid = False
            errors.append(ex.error)

        return ScanValidation(is_valid, errors, warnings)

    def cancel_scan(self, scan_id):
        """attempts to cancel the job associated with a scan

        :param scan_id: The unique identifier of the Scan process.
        :type scan_id: int
        """

        # cancel primary scan job first!
        scan = Scan.objects.select_related('job', 'job__job_type')
        scan = scan.get(pk=scan_id)
        if scan.job.status in ['RUNNING', 'PENDING', 'QUEUED']:
            scan_job_cancel_msg = create_cancel_jobs_messages([scan.job.id], timezone.now())
            CommandMessageManager().send_messages(scan_job_cancel_msg)

        # cancel all ingest jobs associated with scan
        relevant_ingests = Ingest.objects.get_ingests_by_scan(scan_id)
        job_ids = []
        for ingest in relevant_ingests:
            try:
                if ingest.job and ingest.job.status in ['RUNNING', 'PENDING', 'QUEUED']:
                    job_ids.append(ingest.job.id)
                else:
                    if not ingest.job:
                        logger.info("Ingest %d not canceled due to no job existing.", ingest.id)
            except ex:
                if ingest.job: 
                    logger.warning("Job %d was not canceled.", ingest.job.id)
                logger.exception("Error in attempting to cancel ingest job.")
        if len(job_ids) > 0:
            msgs = create_cancel_jobs_messages(job_ids, timezone.now())
            CommandMessageManager().send_messages(msgs)

        if scan.job.status in ['RUNNING', 'PENDING', 'QUEUED']:
            job_ids.append(scan.job.id)
        return job_ids

class Scan(models.Model):
    """Represents an instance of a Scan process which will run and detect files
    in a workspace for ingest

    :keyword name: The identifying name of this Scan process
    :type name: :class:`django.db.models.CharField`
    :keyword title: The human-readable name of this Scan process
    :type title: :class:`django.db.models.CharField`
    :keyword description: An optional description of this Scan process
    :type description: :class:`django.db.models.TextField`

    :keyword configuration: JSON configuration for this Scan process
    :type configuration: :class:`django.contrib.postgres.fields.JSONField`
    :keyword dry_run_job: The job that is performing the Scan process as dry run
    :type dry_run_job: :class:`django.db.models.ForeignKey`
    :keyword job: The job that is performing the Scan process with ingests
    :type job: :class:`django.db.models.ForeignKey`

    :keyword file_count: Number of files identified by last execution of Scan
    :type file_count: :class:`django.db.models.BigIntegerField`
    :keyword created: When the Scan process was created
    :type created: :class:`django.db.models.DateTimeField`
    :keyword last_modified: When the Scan process was last modified
    :type last_modified: :class:`django.db.models.DateTimeField`
    """

    name = models.CharField(max_length=50, unique=True, db_index=True)
    title = models.CharField(blank=True, max_length=50, null=True)
    description = models.TextField(blank=True, null=True)

    configuration = django.contrib.postgres.fields.JSONField(default=dict)

    dry_run_job = models.ForeignKey('job.Job', blank=True, null=True, on_delete=models.PROTECT, related_name='+')
    job = models.ForeignKey('job.Job', blank=True, null=True, on_delete=models.PROTECT, related_name='+')

    file_count = models.BigIntegerField(blank=True, null=True)

    created = models.DateTimeField(auto_now_add=True)
    last_modified = models.DateTimeField(auto_now=True)

    objects = ScanManager()

    def get_scan_configuration(self):
        """Returns the configuration for this Scan process

        :returns: The configuration for this Scan process
        :rtype: :class:`ingest.scan.configuration.scan_configuration.ScanConfiguration`
        """

        return ScanConfigurationV6(self.configuration).get_configuration()

    def get_v6_configuration_json(self):
        """Returns the scan configuration in v6 of the JSON schema

        :returns: The scan configuration in v6 of the JSON schema
        :rtype: dict
        """

        #schemas are identical except for version number, just return dict with version stripped
        return rest_utils.strip_schema_version(self.configuration)

    class Meta(object):
        """meta information for database"""
        db_table = 'scan'
        indexes = [GinIndex(fields=['name'])]

StrikeValidation = namedtuple('StrikeValidation', ['is_valid', 'errors', 'warnings'])

class StrikeManager(models.Manager):
    """Provides additional methods for handling Strike processes
    """

    @transaction.atomic
    def create_strike(self, name, title, description, configuration):
        """Creates a new Strike process with the given configuration and returns the new Strike model. The Strike model
        will be saved in the database and the job to run the Strike process will be placed on the queue. All changes to
        the database will occur in an atomic transaction.

        :param name: The identifying name of this Strike process
        :type name: string
        :param title: The human-readable name of this Strike process
        :type title: string
        :param description: A description of this Strike process
        :type description: string
        :param configuration: The Strike configuration
        :type configuration: :class:`ingest.strike.configuration.strike_configuration.StrikeConfiguration`
        :returns: The new Strike process
        :rtype: :class:`ingest.models.Strike`

        :raises :class:`ingest.strike.configuration.exceptions.InvalidStrikeConfiguration`: If the configuration is
            invalid.
        """

        strike = Strike()
        strike.name = name
        strike.title = title
        strike.description = description
        # Validate the configuration, no exception is success
        if configuration:
            configuration.validate()
            strike.configuration = configuration.get_dict()
        strike.save()

        strike_type = self.get_strike_job_type()

        job_data = Data()
        job_data.add_value(JsonValue('STRIKE_ID', strike.id))
        event_description = {'strike_id': strike.id}
        event = TriggerEvent.objects.create_trigger_event('STRIKE_CREATED', None, event_description, now())
        strike.job = Queue.objects.queue_new_job_v6(strike_type, job_data, event)
        strike.save()
        CommandMessageManager().send_messages(create_process_job_input_messages([strike.job.id]))

        return strike


    @transaction.atomic
    def edit_strike(self, strike_id, title=None, description=None, configuration=None):
        """Edits the given Strike process and saves the changes in the database. All database changes occur in an atomic
        transaction. An argument of None for a field indicates that the field should not change.

        :param strike_id: The unique identifier of the Strike process to edit
        :type strike_id: int
        :param title: The human-readable name of this Strike process
        :type title: string
        :param description: A description of this Strike process
        :type description: string
        :param configuration: The Strike process configuration
        :type configuration: :class:`ingest.strike.configuration.strike_configuration.StrikeConfiguration`

        :raises :class:`ingest.strike.configuration.exceptions.InvalidStrikeConfiguration`: If the configuration is
            invalid.
        """

        strike = Strike.objects.get(pk=strike_id)

        # Validate the configuration, no exception is success
        if configuration:
            configuration.validate()
            strike.configuration = configuration.get_dict()

        # Update editable fields
        if title:
            strike.title = title
        if description:
            strike.description = description
        strike.save()

    def get_strike_job_type(self):
        """Returns the Scale Strike job type

        :returns: The Strike job type
        :rtype: :class:`job.models.JobType`
        """

        return JobType.objects.get(name='scale-strike', version='1.0.0')

    def get_strikes(self, started=None, ended=None, names=None, order=None):
        """Returns a list of Strike processes within the given time range.

        :param started: Query Strike processes updated after this amount of time.
        :type started: :class:`datetime.datetime`
        :param ended: Query Strike processes updated before this amount of time.
        :type ended: :class:`datetime.datetime`
        :param names: Query Strike processes associated with the name.
        :type names: list[string]
        :param order: A list of fields to control the sort order.
        :type order: list[string]
        :returns: The list of Strike processes that match the time range.
        :rtype: list[:class:`ingest.models.Strike`]
        """

        # Fetch a list of strikes
        strikes = Strike.objects.select_related('job', 'job__job_type').defer('configuration')

        # Apply time range filtering
        if started:
            strikes = strikes.filter(last_modified__gte=started)
        if ended:
            strikes = strikes.filter(last_modified__lte=ended)

        # Apply additional filters
        if names:
            strikes = strikes.filter(name__in=names)

        # Apply sorting
        if order:
            strikes = strikes.order_by(*order)
        else:
            strikes = strikes.order_by('last_modified')
        return strikes

    def get_details(self, strike_id, is_staff=False):
        """Returns the Strike process for the given ID with all detail fields included.

        :param strike_id: The unique identifier of the Strike process.
        :type strike_id: int
        :param is_staff: Whether the requesting user is a staff member
        :type is_staff: bool
        :returns: The Strike process with all detail fields included.
        :rtype: :class:`ingest.models.Strike`
        """

        strike = Strike.objects.select_related('job', 'job__job_type').get(pk=strike_id)
        strike.admin_view = is_staff
        return strike

    def validate_strike_v6(self, configuration):
        """Validates the given configuration for creating a new strike process

        :param configuration: The strike configuration
        :type configuration: dict
        :returns: The strike validation
        :rtype: :class:`strike.models.StrikeValidation`
        """

        is_valid = True
        errors = []
        warnings = []

        try:
            config = StrikeConfigurationV6(configuration, do_validate=True).get_configuration()
            warnings = config.validate()
        except InvalidStrikeConfiguration as ex:
            is_valid = False
            errors.append(ex.error)

        return StrikeValidation(is_valid, errors, warnings)


class Strike(models.Model):
    """Represents an instance of a Strike process which will run and detect incoming files in a directory for ingest

    :keyword name: The identifying name of this Strike process
    :type name: :class:`django.db.models.CharField`
    :keyword title: The human-readable name of this Strike process
    :type title: :class:`django.db.models.CharField`
    :keyword description: An optional description of this Strike process
    :type description: :class:`django.db.models.TextField`

    :keyword configuration: JSON configuration for this Strike process
    :type configuration: :class:`django.contrib.postgres.fields.JSONField`
    :keyword job: The job that is performing the Strike process
    :type job: :class:`django.db.models.ForeignKey`

    :keyword created: When the Strike process was created
    :type created: :class:`django.db.models.DateTimeField`
    :keyword last_modified: When the Strike process was last modified
    :type last_modified: :class:`django.db.models.DateTimeField`
    """

    name = models.CharField(max_length=50, unique=True)
    title = models.CharField(blank=True, max_length=50, null=True)
    description = models.TextField(blank=True, null=True)

    configuration = django.contrib.postgres.fields.JSONField(default=dict)
    job = models.ForeignKey('job.Job', blank=True, null=True, on_delete=models.PROTECT)

    created = models.DateTimeField(auto_now_add=True)
    last_modified = models.DateTimeField(auto_now=True)

    objects = StrikeManager()

    def get_strike_configuration(self):
        """Returns the configuration for this Strike process

        :returns: The configuration for this Strike process
        :rtype: :class:`ingest.strike.configuration.strike_configuration.StrikeConfiguration`
        """

        return StrikeConfigurationV6(self.configuration).get_configuration()

    def get_v6_configuration_json(self):
        """Returns the strike configuration in v6 of the JSON schema

        :returns: The strike configuration in v6 of the JSON schema
        :rtype: dict
        """

        sanitize = True
        if hasattr(self, 'admin_view'):
            sanitize = (not self.admin_view)
        return rest_utils.strip_schema_version(convert_strike_config_to_v6_json(self.get_strike_configuration(),sanitize=sanitize).get_dict())

    class Meta(object):
        """meta information for database"""
        db_table = 'strike'
