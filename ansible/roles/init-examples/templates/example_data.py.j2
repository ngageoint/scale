import storage.models
import job.models
from job.configuration.interface.job_interface import JobInterface
import ingest.models
from recipe.configuration.definition.recipe_definition import RecipeDefinition
import recipe.models
import storage.models
import trigger.models
import trigger.handler as trigger_handler

nfs_server="{{ nfs_server }}"
registry="{{ docker_registry }}"
docker_tag="{{ example_image_tag }}"

# Workspaces
if not storage.models.Workspace.objects.filter(name="raw").exists():
    storage.models.Workspace.objects.create(name="raw", title="raw", description="Raw ingested data",
        base_url="http://{{ example_server }}:8080/raw",
        json_config={
        "version": "1.0", "broker": {"mount": "%s:/raw" % nfs_server, "type": "nfs"}}).save()

if not storage.models.Workspace.objects.filter(name="products").exists():
    storage.models.Workspace.objects.create(name="products", title="products", description="Product storage",
        base_url="http://{{ example_server }}:8080/products",
        json_config={
        "version": "1.0", "broker": {"mount": "%s:/products" % nfs_server, "type": "nfs"}}).save()

# Triggers
if not trigger.models.TriggerRule.objects.filter(name="landsat-parse").exists():
    rule_handler = trigger_handler.get_trigger_rule_handler("INGEST")
    trigger_rule = rule_handler.create_trigger_rule({
        "version": "1.0",
        "condition": {
            "media_type": "application/x-tar",
            "data_types": ["landsat"]
        },
        "data": {
            "input_data_name": "infile",
            "workspace_name": "products"
        }
    }, "landsat-parse", True)
if not trigger.models.TriggerRule.objects.filter(name="binary-ingest").exists():
    rule_handler = trigger_handler.get_trigger_rule_handler("INGEST")
    trigger_rule = rule_handler.create_trigger_rule({
        "version": "1.0",
        "condition": {
            "media_type": "application/octet-stream",
            "data_types": []
        },
        "data": {
            "input_data_name": "infile",
            "workspace_name": "products"
        }
    }, "binary-ingest", True)
if not trigger.models.TriggerRule.objects.filter(name="binary-parse").exists():
    rule_handler = trigger_handler.get_trigger_rule_handler("PARSE")
    trigger_rule = rule_handler.create_trigger_rule({
        "version": "1.0",
        "condition": {
            "media_type": "application/octet-stream",
            "data_types": []
        },
        "data": {
            "input_data_name": "infile",
            "workspace_name": "products"
        }
    }, "binary-parse", True)

# Job types
if not job.models.JobType.objects.filter(name="landsat-parse").exists():
    jt = job.models.JobType.objects.create_job_type("landsat-parse", "1.0.0",
                                                    JobInterface({"output_data": [
                                                        {"media_type": "image/tiff", "required": True, "type": "file", "name": "multispectral"},
                                                        {"media_type": "image/tiff", "required": True, "type": "file", "name": "panchromatic"},
                                                        {"media_type": "image/tiff", "required": True, "type": "file", "name": "thermal"}
                                                    ],
                                                        "shared_resources": [],
                                                        "command_arguments": "${infile} ${job_output_dir}",
                                                        "input_data": [
                                                            {"media_types": ["application/octet-stream"], "required": True, "type": "file", "name": "infile"}],
                                                        "version": "1.0", "command": "./parse_landsat.sh"}),
                                                    description="Parse landsat multi-tif files in tar.gz archives",
                                                    docker_image="%slandsat-parse_1.0:%s" % (registry, docker_tag),
                                                    priority=200, timeout=300, max_tries=3, cpus_required=0.25, mem_required=512.)
    jt.title = "Landsat Parse"
    jt.save()
if not job.models.JobType.objects.filter(name="binary-parse").exists():
    trigger_rule = trigger.models.TriggerRule.objects.get(name="binary-ingest")
    assert(trigger_rule is not None)
    jt = job.models.JobType.objects.create_job_type("binary-parse", "1.0.0",
            JobInterface({"output_data": [],
            "shared_resources": [],
            "command_arguments": "${infile} ${job_output_dir}",
            "input_data": [
                {"media_types": ["application/octet-stream"], "required": True, "type": "file", "name": "infile"}],
            "version": "1.0", "command": "parse_binary.sh"}),
        description="Parse arbitrary binary files extracting the date from the file metadata",
        docker_image="%sparse-binary_1.0:%s" % (registry, docker_tag),
        priority=200, timeout=300, max_tries=1, cpus_required=0.25, mem_required=100.,
        trigger_rule=trigger_rule)
    jt.title = "Binary File Parse"
    jt.save()
if not job.models.JobType.objects.filter(name="landsat-ndwi").exists():
    jt = job.models.JobType.objects.create_job_type("landsat-ndwi", "1.0.0",
            JobInterface({"output_data": [
                {"media_type": "image/tiff", "required": True, "type": "file", "name": "ndwi"}],
            "shared_resources": [],
            "command_arguments": "${msi} ${job_output_dir}",
            "input_data": [
                {"media_types": ["image/tiff"], "required": True, "type": "file", "name": "msi"}],
            "version": "1.0", "command": "python landsat_ndwi.py"}),
        description="Perform NDWI on landsat 8 data.",
        docker_image="%slandsat-ndwi_1.0:%s" % (registry, docker_tag),
        priority=250, timeout=300, max_tries=3, cpus_required=0.5, mem_required=512.)
    jt.title = "Landsat NDWI"
    jt.save()
if not job.models.JobType.objects.filter(name="landsat-tiles").exists():
    jt = job.models.JobType.objects.create_job_type("landsat-tiles", "1.0.0",
                                                    JobInterface({"output_data": [
                                                        {"required": True, "type": "files", "name": "tiles"}],
                                                        "shared_resources": [],
                                                        "command_arguments": "${image} ${job_output_dir}",
                                                        "input_data": [
                                                            {"media_types": ["image/tiff"], "required": True, "type": "file", "name": "image"}],
                                                        "version": "1.0", "command": "./landsat_tiles.sh"}),
                                                    description="Generate map tiles for a landsat 8 product.",
                                                    docker_image="%slandsat-tiles_1.0:%s" % (registry, docker_tag),
                                                    priority=250, timeout=300, max_tries=3, cpus_required=0.5, mem_required=512.)
    jt.title = "Landsat Tiles"
    jt.save()
if not job.models.JobType.objects.filter(name="ace").exists():
    jt = job.models.JobType.objects.create_job_type("ace", "1.0.0",
                                                    JobInterface({"output_data": [
                                                        {"media_type": "image/tiff", "required": True, "type": "file", "name": "results"}],
                                                        "shared_resources": [],
                                                        "command_arguments": "${image} ${job_output_dir}",
                                                        "input_data": [
                                                            {"media_types": ["image/tiff"], "required": True, "type": "file", "name": "image"}],
                                                        "version": "1.0", "command": "./runOpticks.sh"}),
                                                    description="Generate Principal Components image.",
                                                    docker_image="%sace_1.0:%s" % (registry, docker_tag),
                                                    priority=250, timeout=300, max_tries=3, cpus_required=2., mem_required=1024.)
    jt.title = "Adaptive Cosine Estimation"
    jt.save()
if not job.models.JobType.objects.filter(name="vash").exists():
    trigger_rule = trigger.models.TriggerRule.objects.get(name="binary-parse")
    assert(trigger_rule is not None)
    jt = job.models.JobType.objects.create_job_type("vash", "1.0.0",
            JobInterface({"output_data": [
                {"media_type": "image/jpeg", "required": True, "type": "file", "name": "results"}],
            "shared_resources": [],
            "command_arguments": "${infile} ${job_output_dir}",
            "input_data": [
                {"media_types": ["application/octet-stream"], "required": True, "type": "file", "name": "infile"}],
            "version": "1.0", "command": "./run.sh"}),
        description="Generate a Visual Hash (vash) of the data.",
        docker_image="%svash_1.0:%s" % (registry, docker_tag),
        priority=250, timeout=300, max_tries=1, cpus_required=0.5, mem_required=100.,
        trigger_rule=trigger_rule)
    jt.title = "Visual Hash"
    jt.save()
if not job.models.JobType.objects.filter(name="pca").exists():
    jt = job.models.JobType.objects.create_job_type("pca", "1.0.0",
            JobInterface({"output_data": [
                {"media_type": "image/tiff", "required": True, "type": "file", "name": "pca"}],
            "shared_resources": [],
            "command_arguments": "${image} ${job_output_dir}",
            "input_data": [
                {"media_types": ["image/tiff"], "required": True, "type": "file", "name": "image"}],
            "version": "1.0", "command": "./runOpticks.sh"}),
        description="Generate Principal Components image.",
        docker_image="%spca_1.0:%s" % (registry, docker_tag),
        priority=250, timeout=300, max_tries=3, cpus_required=2., mem_required=1024.)
    jt.title = "Principal Components Analysis"
    jt.save()

try:
    ingest_jt = job.models.JobType.objects.filter(name="scale-ingest")
    if ingest_jt.exists():
        ingest_jt = ingest_jt.first()
        if ingest_jt.mem_required != 512.:
            ingest_jt.mem_required = 512.
            ingest_jt.save()
except:
    print("scale-ingest not found! did you load_all_data?")

# Recipes
if not recipe.models.RecipeType.objects.filter(name="landsat").exists():
    trigger_rule = trigger.models.TriggerRule.objects.get(name="landsat-parse")
    assert(trigger_rule is not None)
    r = recipe.models.RecipeType.objects.create_recipe_type("landsat", "1.0.0", "Landsat processing",
            "Perform standard Landsat ingest processing", RecipeDefinition({
                "version": "1.0",
                "input_data": [
                    {
                        "name": "infile",
                        "type": "file",
                        "media_types": ["application/x-tar"]
                    }
                ],
                "jobs": [
                    {
                        "name": "parse",
                        "job_type": {
                            "name": "landsat-parse",
                            "version": "1.0.0"
                        },
                        "recipe_inputs": [
                            {
                                "recipe_input": "infile",
                                "job_input": "infile"
                            }
                        ]
                    },
                    {
                        "name": "ndwi",
                        "job_type": {
                            "name": "landsat-ndwi",
                            "version": "1.0.0"
                        },
                        "dependencies": [
                            {
                                "name": "parse",
                                "connections": [
                                    {"output": "multispectral", "input": "msi"}
                                ]
                            }
                        ]
                    },
                    {
                        "name": "tiles",
                        "job_type": {
                            "name": "landsat-tiles",
                            "version": "1.0.0"
                        },
                        "dependencies": [
                            {
                                "name": "ndwi",
                                "connections": [
                                    {"output": "ndwi", "input": "image"}
                                ]
                            }
                        ]
                    }
                ]
            }), trigger_rule)

# Strike processes
if not ingest.models.Strike.objects.filter(name="landsat").exists():
    ingest.models.Strike.objects.create_strike_process("landsat", "Landsat", "Landsat GeoTIFF Ingest",
	{
	    "files_to_ingest": [
		{
		    "data_types": [
			"landsat"
		    ],
		    "filename_regex": r".*tar.gz",
		    "workspace_name": "raw",
		    "workspace_path": "landsat"
		}
	    ],
	    "mount": "%s:/ingest/landsat" % nfs_server,
	    "transfer_suffix": "_tmp",
	    "version": "1.0"
	}).save()
if not ingest.models.Strike.objects.filter(name="data").exists():
    ingest.models.Strike.objects.create_strike_process("data", "Binary data", "Arbitrary binary data ingest",
	{
	    "files_to_ingest": [
		{
		    "data_types": [],
		    "filename_regex": r".*.bin",
		    "workspace_name": "raw",
		    "workspace_path": "binary"
		}
	    ],
	    "mount": "%s:/ingest/binary" % nfs_server,
	    "transfer_suffix": "_tmp",
	    "version": "1.0"
	}).save()

# Country Data
if storage.models.CountryData.objects.count() == 0:
    from osgeo import ogr
    import os
    from django.contrib.gis.geos.geometry import GEOSGeometry
    from datetime import datetime

    driver = ogr.GetDriverByName('ESRI Shapefile')
    ds = driver.Open('/tmp/TM_WORLD_BORDERS-0.3.shp', 0)
    mtime = datetime.utcfromtimestamp(os.stat('/tmp/TM_WORLD_BORDERS-0.3.shp').st_mtime)
    layer = ds.GetLayer()
    for feature in layer:
        name = feature.GetFieldAsString('NAME')
        print('Importing %s' % name)
        fips = feature.GetFieldAsString('FIPS')
        iso2 = feature.GetFieldAsString('ISO2')
        iso3 = feature.GetFieldAsString('ISO3')
        iso_num = feature.GetFieldAsString('UN')
        geom = feature.GetGeometryRef()
        wkt = geom.ExportToWkt()
        storage.models.CountryData.objects.create(name=name,
                                                  fips=fips,
                                                  iso2=iso2,
                                                  iso3=iso3,
                                                  iso_num=iso_num,
                                                  border=GEOSGeometry(wkt),
                                                  effective=mtime).save()
